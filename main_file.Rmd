---
title: "DataSience_FinalProject"
author: "Jan Steinwender & Paul Pavlis"
date: "2020-10-28"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Clean the environment variables (*Temporary*)
*Remove this whole header before handing the project in. This is just so that working with the document is easier*
```{r}
rm(list = ls())
```

# Load needed libraries

```{r}
library(tidyverse)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(nnet)
library(rpart)
library(keras)
```
# Data wrangling

## Data import from csv file

Die Daten werden mit *read.csv* eingelesen, da dadurch alle Spalten richtig eingelesen werden, 
was aufgrund der Spalte **Cuisine.Style** anders nicht so leicht geht, da diese Spalte ein
Python List object enthält, was als Trennzeichen das Gleiche Trennzeichen verwendet wie 
bei der Trennung der verschiedenen Spalten.

Außerdem werden leere Einträge durch NA Werte ersetzt, da Funktionen mit diesen besonders umgehen können.

```{r}
restaurant_data = read.csv(file = "restaurants_data.csv")
# Set empty data entries to NA
restaurant_data = restaurant_data %>% na_if("") 
```

## Clean the data

### Rename and remove columns

Die Spaltennamen werden auf angenehmerer Art dargestellt und die Spalten welche keine benötigten Infos liefern e.gg
**X**, **URL_TA** & **ID_TA** werden entfernt.

```{r}
restaurant_data = as_tibble(restaurant_data)

restaurant_data = restaurant_data %>%
  rename("Cuisine_Style" = Cuisine.Style) %>%
  rename("Price_Range" = Price.Range) %>%
  rename("Review_Count" = Number.of.Reviews)

# Remove useless columns
restaurant_data = restaurant_data %>%
  mutate(X = NULL, URL_TA = NULL, ID_TA = NULL) 
```

### Correct the column types

Die Spalte **City** wird von einer Textvariable zu einer kategorialen Faktorvariable geändert,
da die Städte öfter vorkommen und dadurch mehr Infos aus der Spalte geholt werden können.
Diese Variable besitzt 31 Ausprägungen

Die Spalten **Price_Range** und **Rating** werden aus den selben Gründen ebenso in einen Faktor umgewandelt.
Die Variable **Price_Range** besitzt 3 Ausprägungen, die für leichtere Verständlichkeit umbenannt werden in:
*low*, *medium* & *high*.
Die Variable **Rating** besitzt 9 Ausprägungen.


```{r}
# Change from character to factor
restaurant_data = restaurant_data %>% mutate(City = as_factor(City)) 

# Change from character to factor
restaurant_data = restaurant_data %>% mutate(Price_Range = as_factor(Price_Range)) 
# Rename the levels
restaurant_data = restaurant_data %>% mutate(Price_Range = fct_recode(
  Price_Range,
  "high" = "$$$$",
  "medium" = "$$ - $$$",
  "low" = "$"
)) 

# Set invalid entries with a rating of -1 to NA
restaurant_data$Rating = restaurant_data$Rating %>% na_if("-1") 
# Change from character to factor
restaurant_data = restaurant_data %>% mutate(Rating = as_factor(Rating)) 
```

### Check duplicated and NULL values

Ursprünglich enthält der Datensatz *286* Datensätze die doppelt vorkommen. Diese werden entfernt.

Insgsamt enthält der Datensatz *123992* NA Werte. Diese sind wie folgt auf die einzelnen Spalten aufgeteilt:

```{r}
duplicated(restaurant_data) %>% sum()
# Remove duplicates
restaurant_data = restaurant_data %>% distinct() 


is.na(restaurant_data) %>% sum()
sapply(restaurant_data, function(x) sum(is.na(x)))
```

# Explorative Datenanalyse

Der Datensatz handelt von TripAdvisor Bewertungen vieler Restaurants von 31 europäischen Städten.

Der endgültige Datensatz mit dem wir in diesem Projekt arbeiten werden, besteht aus *acht* Variablen (Spalten) mit *125.238* Observationen (Zeilen).
Diese beinhalten:

**Name**: Name des Restaurants - Textvariable (unique)

**City**: Stadt in der sich das Restaurant befindet - Kategoriale Faktorvariable mit 31 Ausprägungen (London mit 18113 Einträgen, Paris mit 14867 Einträgen, ...)

**Cuisine_Style**: Essensrichtungen des Restaurants - Textvariable (grundsätzlich besteht diese aus mehreren Faktoren innerhalb eines Python list Objektes / 31222 NA Werte)

**Ranking**: Rang des Restaurants im Vergleich zu allen anderen Restaurants in der Stadt - Diskrete Variable (Min: 1, Mean: 3658, Median: 2256, Max: 16444 / 9370 NA Werte)

**Rating**: Bewertung des Restaurants von 1-5 in 0.5 Schritten - Kategoriale Faktorvariable mit 9 Ausprägungen (Bewertung 4 mit 39841 Einträgen, 4.5 mit 31325 Einträgen, ... / 9389 NA Werte)

**Price_Range**: Preisbewertung - Kategoriale Faktorvariable mit 3 Ausprägungen (medium mit 54302 Einträgen, high mit 4306 Einträgen und low mit 18988 Einträgen / 47642 NA Werte)

**Review_Count**: Anzahl der Reviews - Diskrete Variable (Min: 2, Mean: 125.2, Median: 32, Max: 16478 / 17062 NA Werte)

**Reviews**: Zwei Reviews des Restaurants und die Daten, an dem die Reviews geschrieben wurden - Textvariable (als Python list Objekt abgespeichert)

```{r}
restaurant_data
str(restaurant_data)
summary(restaurant_data)
```

## Anzahl der Restaurants pro Stadt

Hier zu sehen ist die Verteilung der Anzahl der Restaurants pro Stadt absteigend geordnet.
Zusätzlich ist noch die Verteilung der Preis Einteilung pro Stadt zu sehen. 

Gut zu sehen ist, dass in dem Datensatz Städte wie *London*, *Paris* sehr viele Restaurants besitzen. (Bereich ~15.000+)
Danach ist ein stärkerer Abfall an Vorkommnissen zu sehen und die Städte *Luxenburg* und *Ljubljana* besitzen am wenigsten Restuarants hier. (<1000)

Auch zu erkennen ist, dass die meisten Restaurants in so gut wie allen Städten in die Preis Klasse *medium* fallen. Am wenigsten Restaurants sind in der Klasse *high*.
Der Anteil an nicht klassifizierter Restaurants (NA) ist sehr hoch und ist ein beträchtlicher Anteil.

```{r}
city_price_graph <-
  mutate(restaurant_data, City = fct_infreq(City)) %>%
  mutate(Price_Range = fct_relevel(Price_Range,
                                   "high", "medium", "low")) %>%
  ggplot(aes(x = City)) + geom_bar(aes(fill = Price_Range))

city_price_graph + ggtitle("Anzahl der Restaurants pro Stadt",
                           subtitle = paste0("Anzahl der Datensätze: ",
                                             length(which(
                                               !is.na(restaurant_data$City)
                                             )))) +
  xlab("Stadt") +
  ylab("Anzahl der Vorkommnisse") +
  theme_bw() +
  theme(axis.text.x = element_text(
    angle = 90,
    vjust = 0.5,
    hjust = 1
  )) + 
  scale_fill_brewer(type = "qual", palette = 4, na.value = "grey50")
```

## Anzahl der Restaurants Ratings

Hier zu sehen ist die Verteilung der Anzahl der Rating Stufen.

Gut zu erkennen ist, dass die Ratings 4 und 4.5 am häufigsten gegeben werden und Ratings wie 3 oder 5 viel seltener.
Ratings <= 2.5 kommen am seltensten vor. Dies könnte sich dadurch erklären lassen, dass diese Restaurants sich nicht besonders gut halten werden und wahrscheinlich öfters schließen müssen als Restauraunts mit besseren Bewertungen.

```{r}
ratings_graph = restaurant_data %>%
  filter(!is.na(Rating)) %>%
  ggplot(aes(x = Rating)) + geom_bar(aes(fill = Rating))

ratings_graph + ggtitle("Anzahl der Restaurant Ratings Stufen",
                        subtitle = paste0("Anzahl der Datensätze: ", length(which(
                          !is.na(restaurant_data$Rating)
                        )))) +
  xlab("Rating Ebene") +
  ylab("Anzahl der Vorkommnisse") +
  theme_bw() + 
  scale_fill_brewer(type = "seq", palette = 3)
```

## Anzahl der Restaurant Ratings pro Preisklasse

Hier zu sehen ist die Verteilung der Anzahl der Rating Stufen pro Preisklasse.

Es ist ersichtlich, dass Restaurants mit einer niedrigen Preisklasse tendenziell eher weniger hohe Bewertungen haben (im Vergleich zu den anderen Preisklassen)
Restaurants in einer hohen Preisklasse hingegen besitzen höhere Ratings welche im Schnitt 4 oder höher sind.

Ein weiteres interessantes Merkmal ist, dass Restaurants ohne Preisklasseneinstufung tendenziell viel mehr 5 Sterne Bewertungen haben.
Dies kann entweder ein statistischer Zufall sein oder es könnte daran liegen, dass diese Restaurants nicht in traditionelle Preisklassen eingeteilt werden können und dadurch Leute besser ansprechen (was aber eher weit hergeholt ist).

```{r}
ratings_price_graph = restaurant_data %>%
  filter(!is.na(Rating)) %>%
  ggplot(aes(x = Rating)) + geom_bar(aes(fill = Rating)) + facet_wrap( ~Price_Range)

ratings_price_graph + ggtitle("Anzahl der Restaurant Ratings Stufen pro Preisklasse",
                        subtitle = paste0("Anzahl der Datensätze: ", length(which(
                          !is.na(restaurant_data$Rating)
                        )))) +
  xlab("Rating Ebene") +
  ylab("Anzahl der Vorkommnisse") +
  theme_bw() + 
  scale_fill_brewer(type = "seq", palette = 3)
```

## Review Anzahl

Hier zu sehen ist die Verteilung der Anzahl der Review Bewertungen.

Dieser Graph gruppiert auf der x-Achse die Anzahl der Reviews in 50er Blöcke und stellt davon die Anzahl der Vorkommnisse auf der y-Achse dar.

Hier kann man stark betrachten, dass die Verteilung stark rechts fallend ist und die meisten Vorkommnisse in die Kategorie von 0-50 Reviews fallen.
Dies bedeutet, dass die meisten Restaurants wenig Reviews haben und das nur noch ein sehr kleiner Anteil an Restaurants mehr als 500 Reviews haben.

```{r}
reviewCount_graph = restaurant_data %>% filter(!is.na(Review_Count)) %>% ggplot(aes(x = Review_Count)) + geom_histogram(aes(fill=stat(count)), binwidth = 50)

reviewCount_graph + ggtitle("Verteilung der Review Anzahl",
                        subtitle = paste0("Anzahl der Datensätze: ", length(which(
                          !is.na(restaurant_data$Review_Count)
                        )), " | Binwidth = 50")) +
  xlab("Review Anzahl") +
  ylab("Anzahl der Vorkommnisse") +
  theme_bw() +
  xlim(0, 2500) + ylim(0, 25000) +
  scale_fill_distiller(type = "seq", palette = 5)
```

## Restaurant Ranking erklärt durch Review Anzahl

Hier zu sehen ist die Verteilung des Rankings von Restaurants erklärt durch die Review Anzahl.

Es ist eindeutig ersichtlich, dass Restaurants welche ein hohes Ranking in ihrer Stadt haben, eine dementsprechend höhere Anzahl an Reviews hat.
Dies kann sich dadurch erklären lassen, dass Top-Restaurants öfters besucht werden und dadurch mehr Leute auch eine Bewertung schreiben.

```{r}
ranking_reviewCount_graph = restaurant_data %>% filter(!is.na(Review_Count)) %>% filter(!is.na(Ranking)) %>% ggplot(aes(x = Review_Count, y = Ranking)) +
  geom_point() + geom_smooth(method = "gam")

ranking_reviewCount_graph + ggtitle("Restaurant Ranking erklärt durch Review Anzahl",
                        subtitle = paste0("Anzahl der Datensätze: ", length(which(
                          !is.na(restaurant_data$Ranking)
                        )))) +
  xlab("Review Anzahl") +
  ylab("Ranking des Restaurants") +
  theme_bw() +
  scale_y_continuous(trans = "reverse", limits = c(17000, 1))
```

# Modellierung 

Auswahl des Merkmals zur Vorhersage:

Auswahl: Ranking

Das Ranking sollte ein gutes Merkmal für die Vorhersage sein, da dieser gut durch die anderen Parameter vorhersagbar sein sollte (in gewissen Grenzen) und da er recht interessant für neue Restaurants sein könnte.

Dadurch könnte man dann schauen, in welcher Stadt es sich auszahlen würde, Restaurants zu öffnen, anhand des jeweiligen Rankings im Vergleich zu den anderen Restaurants in der Stadt.

Außerdem hatten wir in der LV und bei den Übungen sehr viel mit Klassifikation zu tun und wollten dies auch einmal mit einem Reggressionsbeispiel durchprobieren.

## Spezielle Aufbereitung

Name und Reviewtext bringen keinen Mehrwert beim Vorhersagen und werden deswegen im ersten Schritt entfernt. Cuisine Style bringt in dem vorhandenen Format ebenfalls nichts.
Zusätzlich werden, da genügend viele Daten vorhanden sind, im nächsten Schritt alle Daten rausgehaut, bei denen Werte fehlen.

```{r}
data_not_null = mutate(restaurant_data, Name = NULL, Reviews = NULL, Cuisine_Style = NULL) %>% drop_na()
```

## Trainings- und Testdaten kreieren

```{r}
N = nrow(data_not_null)
train_ind = sample(1 : N, size = N * 2/3)
trainData = data_not_null[train_ind,]
testData = data_not_null[-train_ind,]
```

```{r}
pp = preProcess(trainData, method = c("center", "scale"))
trainData_scaled = predict(pp, trainData)
testData_scaled = predict(pp, testData)
```

## Linear Regression

Nicht eine von den drei erforderlichen Methoden. Wurde aus Interesse gemacht. Sie ist (wie erwartet) nicht so gut für diesen Anwendungsfall. Eventuell könnte sie noch mehr getuned werden, allerdings sind andere Methoden für diesen Fall attraktiver und (für uns) spannender.

```{r}
m_linearRegression = lm(Ranking ~ ., data = trainData_scaled)

# summary(m_linearRegression)
```

### Berechnung Training Error

```{r}
fitted_linearRegression = predict(m_linearRegression, trainData_scaled)
train_error_linearRegression = mean((fitted_linearRegression - trainData_scaled$Ranking)^2)

train_error_linearRegression
```

### Berechnung Gerneralization Error

```{r}
pred_linearRegression = predict(m_linearRegression, testData_scaled)
test_error_linearRegression = mean((pred_linearRegression - testData_scaled$Ranking)^2)

test_error_linearRegression
```

## Tree Modell (rpart)

```{r}
# m_rpart = rpart(Ranking ~., trainData_scaled)
```

### Parameter Tuning

Getestet zwischen:
Minimale Anzahl in Node bevor Split: 5 - 100
Minimale Anzahl in Node: 5 - 100

Beste Parameter beim Erstelldruchgang: Keine Verbesserung -> Nehmen von 50 in einer Node (minbucket)

```{r}
# tune_rpart = tune.rpart(Ranking ~ ., data = trainData_scaled,
#                                       # # Dauert recht lange, man sieht aber schön
#                                       # # wo die Grenzen sind
#                                       # minsplit = seq(1, 10000, by = 100),
#                                       # minbucket = seq(1, 10000, by = 100),
#                                       minsplit = seq(5, 100, by = 5),
#                                       minbucket = seq(5, 100, by = 2),
#                                       tunecontrol = tune.control(sampling = "fix",
#                                                fix = 2/3))
# 
# 
# tune_rpart
# plot(tune_rpart, color.palette = topo.colors)
```

### Erstellung des getunten Modells

```{r}
m_rpart = rpart(Ranking ~ ., data = trainData_scaled, minbucket = 50)
```

### Berechnung Training Error

```{r}
fitted_rpart = predict(m_rpart, trainData_scaled)
train_error_rpart = mean((fitted_rpart - trainData_scaled$Ranking)^2)

train_error_rpart
```

### Berechnung Gerneralization Error

```{r}
pred_rpart = predict(m_rpart, testData_scaled)
test_error_rpart = mean((pred_rpart - testData_scaled$Ranking)^2)

test_error_rpart
```

## RandomForest

```{r}
# m_randomForest = randomForest(Ranking ~ ., data = trainData_scaled, importance = TRUE, ntree = 100)
```

### Parameter Tuning

Getestet zwischen:
Anzahl der Bäume: 50 - 500
Minimale Größe der einzelnen Nodes: 10 - 1000

Beste Parameter beim Erstelldruchgang: nodesize: 40 | ntree: 100

```{r}
# tune_randomForest = tune.randomForest(Ranking ~ ., data = trainData_scaled,
#                                       ntree = seq(50, 500, by = 20),
#                                       nodesize = seq(10, 100, by = 10),
#                                       tunecontrol = tune.control(sampling = "fix",
#                                                fix = 2/3))
# 
# 
# tune_randomForest
# plot(tune_randomForest, color.palette = topo.colors)
```

### Erstellung des getunten Modells

```{r}
m_randomForest = randomForest(Ranking ~ ., data = trainData_scaled, importance = TRUE, ntree = 100, nodesize = 40)
```

### Berechnung Training Error

```{r}
fitted_randomForest = predict(m_randomForest, trainData_scaled)
train_error_randomForest = mean((fitted_randomForest - trainData_scaled$Ranking)^2)

train_error_randomForest
```

### Berechnung Gerneralization Error

```{r}
pred_randomForest = predict(m_randomForest, testData_scaled)
test_error_randomForest = mean((pred_randomForest - testData_scaled$Ranking)^2)

test_error_randomForest
```


## NNet

Testen des nnet Modells um den Unterschied nochmals zu verdeutlichen zwischen der Qualität von nnet und keras.
(Abgesehen von dem enormen Zeitunterschied)

**Wurde komplett auskommentiert, da es sehr lange dauert**

```{r}
# m_nnet = nnet(Ranking ~ ., data = trainData_scaled, size = 10, lineout = TRUE, decay = 0.2, MaxNWts = 5000)
```

Getestet zwischen:
Size: 10 - 500
decay: 0.05 - 0.3

Beste Parameter beim Erstelldruchgang: size: 90 | decay: 0.1

```{r}
# tune_nnet = tune.nnet(
#   Ranking ~ .,
#   data = trainData_scaled,
#   MaxNWts = 30000,
#   lineout = TRUE,
#   size = seq(10, 500, by = 80),
#   decay = seq(0.05, 0.3, by = 0.05),
#   tunecontrol = tune.control(sampling = "fix",
#                              fix = 2 / 3)
# )
# 
# tune_nnet
# plot(tune_nnet, color.palette = topo.colors)
```

### Erstellung des getunten Modells

***Auskommentiert, da es recht lange braucht***

```{r}
# m_nnet = nnet(Ranking ~ ., data = trainData_scaled, size = 90, lineout = TRUE, decay = 0.1, MaxNWts = 5000)
```

### Berechnung Training Error

```{r}
# fitted_nnet = predict(m_nnet, trainData_scaled)
# train_error_nnet = mean((fitted_nnet - trainData_scaled$Ranking)^2)
# 
# train_error_nnet
```

### Berechnung Gerneralization Error

```{r}
# pred_nnet = predict(m_nnet, testData_scaled)
# test_error_nnet = mean((pred_nnet - testData_scaled$Ranking)^2)
# 
# test_error_nnet
```

## Neural Network (keras -> tensorflow)

### Binary Coding the factors

Eventuell ist es nicht so besonders gut so etwas wie die Stadt hier reinzugeben, da diese unglaublich viele Ausprägungen hat. Generell sind drei Faktoren recht viel.

```{r}
trainData_bcoded_City = to_categorical(as.integer(trainData_scaled$City) - 1)
trainData_bcoded_Rating = to_categorical(as.integer(trainData_scaled$Rating) - 1)
trainData_bcoded_Price_Range = to_categorical(as.integer(trainData_scaled$Price_Range) - 1)

trainData_bound = cbind(
  trainData_bcoded_City,
  trainData_bcoded_Rating,
  trainData_bcoded_Price_Range,
  trainData_scaled$Review_Count
)
trainData_labels = trainData_scaled$Ranking

# str(trainData_scaled)
# 31 + 9 + 3 + 1 = 44 --> input Shape
```

```{r}
testData_bcoded_City = to_categorical(as.integer(testData_scaled$City) - 1)
testData_bcoded_Rating = to_categorical(as.integer(testData_scaled$Rating) - 1)
testData_bcoded_Price_Range = to_categorical(as.integer(testData_scaled$Price_Range) - 1)

testData_bound = cbind(
  testData_bcoded_City,
  testData_bcoded_Rating,
  testData_bcoded_Price_Range,
  testData_scaled$Review_Count
)
testData_labels = testData_scaled$Ranking
```


### Basic model

```{r}
library(keras) # Weniger oft eine Fehlermeldung wenn man sie nochmal aufruft
m_nn_keras <- keras_model_sequential()
m_nn_keras %>% 
  layer_dense(units = 100, activation = "sigmoid", input_shape = c(44)) %>% 
  layer_dense(units = 1, activation = "sigmoid")
```

### Compile the model

```{r}
m_nn_keras %>% compile(
  loss = "mse",
  optimizer = optimizer_rmsprop(),
  metrics = c("mean_absolute_error")
)
summary(m_nn_keras)
```

### Fit train data

```{r}
history_nn_keras <- m_nn_keras %>% fit(
  trainData_bound, trainData_labels, 
  epochs = 10, batch_size = 100, 
  validation_split = 0.2
)
plot(history_nn_keras)
```

### Parameter Tuning

#### Testen von anderen activation functions

```{r}
m_nn_keras <- keras_model_sequential()
m_nn_keras %>% 
  # layer_dense(units = 100, activation = "relu", input_shape = c(44)) %>%
  # layer_dense(units = 1, activation = "relu")
  # layer_dense(units = 100, activation = "softplus", input_shape = c(44)) %>%
  # layer_dense(units = 1, activation = "softplus")
  # layer_dense(units = 100, activation = "exponential", input_shape = c(44)) %>%
  # layer_dense(units = 1, activation = "exponential")
  # layer_dense(units = 100, activation = "softsign", input_shape = c(44)) %>%
  # layer_dense(units = 1, activation = "softsign")
  layer_dense(units = 100, activation = "selu", input_shape = c(44)) %>%
  layer_dense(units = 1, activation = "selu")
  # layer_dense(units = 100, activation = "elu", input_shape = c(44)) %>%
  # layer_dense(units = 1, activation = "elu")
  # layer_dense(units = 100, activation = "exponential", input_shape = c(44)) %>%
  # layer_dense(units = 1, activation = "exponential")

m_nn_keras %>% compile(
  loss = "mse",
  optimizer = optimizer_rmsprop(),
  metrics = c("mean_absolute_error")
)

history_nn_keras <- m_nn_keras %>% fit(
  trainData_bound, trainData_labels, 
  epochs = 10, batch_size = 100, 
  validation_split = 0.2
)
plot(history_nn_keras)
```

**Elu oder Selu sollten als Activation Parameter weiterverwendet und optimiert werden**

#### Testen von Input Units

Input Units getestet zwischen: 10 - 10000

Ergebnis: Bereich unter 300 sollte weiter getestet werden

Erkenntnis: Selu braucht bei uns niedrigere Start Units (Unter 200), damit es nicht auswendig lernt.

```{r}
m_nn_keras <- keras_model_sequential()
m_nn_keras %>% 
  layer_dense(units = 10000, activation = "selu", input_shape = c(44)) %>%
  # layer_dense(units = 1000, activation = "selu", input_shape = c(44)) %>%
  # layer_dense(units = 500, activation = "selu", input_shape = c(44)) %>%
  # layer_dense(units = 300, activation = "selu", input_shape = c(44)) %>%
  # layer_dense(units = 200, activation = "selu", input_shape = c(44)) %>%
  # layer_dense(units = 100, activation = "selu", input_shape = c(44)) %>%
  # layer_dense(units = 50, activation = "selu", input_shape = c(44)) %>%
  layer_dense(units = 1, activation = "selu")

m_nn_keras %>% compile(
  loss = "mse",
  optimizer = optimizer_rmsprop(),
  metrics = c("mean_absolute_error")
)
summary(m_nn_keras)

history_nn_keras <- m_nn_keras %>% fit(
  trainData_bound, trainData_labels, 
  epochs = 10, batch_size = 100, 
  validation_split = 0.2
)
plot(history_nn_keras)
```

#### Testen von batch-size

Ergebnis: Batch-size sollte sehr niedrig sein (Dafür braucht es auch länger): Unter 20 am Besten

```{r}
m_nn_keras <- keras_model_sequential()
m_nn_keras %>% 
  layer_dense(units = 100, activation = "elu", input_shape = c(44)) %>%
  layer_dense(units = 1, activation = "elu")

m_nn_keras %>% compile(
  loss = "mse",
  optimizer = optimizer_rmsprop(),
  metrics = c("mean_absolute_error")
)
summary(m_nn_keras)

history_nn_keras <- m_nn_keras %>% fit(
  trainData_bound, trainData_labels, 
  # epochs = 10, batch_size = 10, 
  # epochs = 10, batch_size = 50,
  epochs = 10, batch_size = 100,
  # epochs = 10, batch_size = 1000, 
  validation_split = 0.2
)
plot(history_nn_keras)
```

#### Test: Deep Learning

Erkanntes Merkmal: Auch nach über 100 Epochen entsteht kein Overfitting. 
Allerdings gibt es meistens ab der 30 Epoche keine Verbesserung mehr.

```{r}
m_nn_keras <- keras_model_sequential()
m_nn_keras %>% 
  # Versuch 1 - Ist auch nach über 50 Epochen nicht unter 15% gegangen -> nicht so gut
  # layer_dense(units = 100, activation = "elu", input_shape = c(44)) %>%
  # layer_dropout(rate = 0.3) %>%
  # layer_dense(units = 10, activation = "elu") %>%
  # layer_dropout(rate = 0.2) %>%
  # layer_dense(units = 1, activation = "elu")
  
  # # Versuch 2 - Lernt schon recht früh auswendig -> 13%
  # layer_dense(units = 1000, activation = "elu", input_shape = c(44)) %>%
  # layer_dropout(rate = 0.3) %>%
  # layer_dense(units = 100, activation = "elu") %>%
  # layer_dropout(rate = 0.2) %>%
  # layer_dense(units = 1, activation = "elu")  

  # # Versuch 3 - Nach 10 Epochen schon relativ am Minimum -> 11,8%
  # # (Pendelt sich nach 30 Epochen bei 11,3% ein)
  # layer_dense(units = 100, activation = "elu", input_shape = c(44)) %>%
  # layer_dropout(rate = 0.3) %>%
  # layer_dense(units = 50, activation = "elu") %>%
  # layer_dropout(rate = 0.2) %>%
  # layer_dense(units = 1, activation = "elu")

  # # Versuch 4 - Pendelt sich um die 12% ein
  # layer_dense(units = 100, activation = "elu", input_shape = c(44)) %>%
  # layer_dropout(rate = 0.3) %>%
  # layer_dense(units = 30, activation = "elu") %>%
  # layer_dropout(rate = 0.2) %>%
  # layer_dense(units = 1, activation = "elu")

  # # Versuch 5 -Pendelt sich um die 13% ein
  # layer_dense(units = 50, activation = "elu", input_shape = c(44)) %>%
  # layer_dropout(rate = 0.3) %>%
  # layer_dense(units = 20, activation = "elu") %>%
  # layer_dropout(rate = 0.2) %>%
  # layer_dense(units = 1, activation = "elu")

  # Versuch 6 - Mehrere hidden Layer machen es nicht besser -> 14%
  layer_dense(units = 100, activation = "elu", input_shape = c(44)) %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 50, activation = "elu") %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 10, activation = "elu") %>%
  layer_dropout(rate = 0.1) %>%
  layer_dense(units = 1, activation = "elu")

m_nn_keras %>% compile(
  loss = "mse",
  optimizer = optimizer_rmsprop(),
  metrics = c("mean_absolute_error")
)
summary(m_nn_keras)

history_nn_keras <- m_nn_keras %>% fit(
  trainData_bound, trainData_labels, 
  epochs = 10, batch_size = 10, 
  # epochs = 30, batch_size = 10, 
  validation_split = 0.2
)
plot(history_nn_keras)
```

### Erstellung des getunten Modells

Es gibt mehrere akzeptable Modelle. 
Eine davon ist Elu mit 20 Input Units und 7 Epochen (Es Overfitted meist ab 7-10 Epochen im Schnitt)
  -> Kommt auf in etwa 11,4% Error
  
Trotzdem haben wir uns nach vielen Durchläufen dazu entschieden, ein Modell mit mehreren hidden layers zu nehmen, da diese mit über zehn verschiedenen Zuteilungen auf Trainings- und Testdaten, konsistent waren. Die mit nur einem hidden layer hatten in 3/10 starke Inkonsistenz und haben zum Beispiel schon in der zweiten Epoche overfitted, was wir vermeiden wollten. Seeden wäre auch ein Option gewesen, hätte aber eher zum selektiven Datenaussuchen geführt, was wir vermeiden wollten damit ein gutes Generalisationsmodell entsteht.

Anmerkung: Beim Testen von den Varianten mit nur einem hidden layer kommt es hin und wieder vor, dass Unglückliche Werte oder Gewichte anfänglich genommen werden und dieses Ergebnis dadurch anders aussieht (zb Früheres Overfitting oder andere weirde Ergebnisse)

```{r}
m_nn_keras <- keras_model_sequential()
m_nn_keras %>% 
  layer_dense(units = 100, activation = "elu", input_shape = c(44)) %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units = 50, activation = "elu") %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 1, activation = "elu")

m_nn_keras %>% compile(
  loss = "mse",
  optimizer = optimizer_rmsprop(),
  metrics = c("mean_absolute_error")
)
summary(m_nn_keras)
save(m_nn_keras, file="keras_model.rda")

history_nn_keras <- m_nn_keras %>% fit(
  trainData_bound, trainData_labels, 
  # 20, da es sonst sehr lange dauert und es nicht wirklich besser wird
  # Es wurde bis 100 epochen getestet und die Unterschiede waren marginal.
  epochs = 20, batch_size = 10, 
  # epochs = 100, batch_size = 10, 
  validation_split = 0.2
)
plot(history_nn_keras)
```

### Berechnung Training Error

```{r}
fitted_nn_keras = predict(m_nn_keras, trainData_bound)
train_error_nn_keras = mean((fitted_nn_keras - trainData_labels)^2)

train_error_nn_keras
```

### Berechnung Gerneralization Error

```{r}
pred_nn_keras = predict(m_nn_keras, testData_bound)
test_error_nn_keras = mean((pred_nn_keras - testData_labels)^2)

test_error_nn_keras
```

## Endgültige Entscheidung

Für unseren Fall der Reggression würden wir uns für das getunte Model von keras/tensorflow entscheiden, da dieses den geringsten Error aufweist. Baummodelle waren ebenfalls akzeptabel mit um die 20% Error, allerdings war das Neuronale Netz um zirka 8-10% besser.

## REST vorbeireitung

Für den REST Server werden einige Variablen benötigt. Diese werden hier exportiert.

```{r}
levels_city = levels(trainData_scaled$City)
levels_price_range = levels(trainData_scaled$Price_Range)
levels_rating = levels(trainData_scaled$Rating)

save(levels_city, levels_price_range, levels_rating, pp, file="variables.rda")
```





